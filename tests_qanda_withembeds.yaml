# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: 'Tests mit LLM embeddings'


# Global provider configuration
providers:
  - file://retrieve_phi.py

defaultTest:
  options:
    provider:
      embedding: ollama:embeddings:mxbai-embed-large
  assert:
    - type: similar
      value: "{{fact}}"
      threshold: 0.7


prompts:
 - &basic_qanda |
   Sie sind ein Assistent für Fragen und Antworten.
   
   Kontext: {{context}}
   Frage: {{query}}
   
   Beantworten Sie die Frage präzise basierend auf dem gegebenen Kontext.
   Verwenden Sie nur Informationen, die im Kontext enthalten sind.

tests: file://data/tests_qanda_lazy_context.csv